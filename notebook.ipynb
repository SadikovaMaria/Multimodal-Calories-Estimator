{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c13e425",
   "metadata": {},
   "source": [
    "Этап 1. Исследовательский анализ (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, random, pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "BASE_DIR   = Path(\"data/nutrition/data\")\n",
    "IMG_DIR    = BASE_DIR / \"images\"\n",
    "DISH_CSV   = BASE_DIR / \"dish.csv\"\n",
    "INGR_CSV   = BASE_DIR / \"ingredients.csv\"\n",
    "\n",
    "for p in [BASE_DIR, IMG_DIR, DISH_CSV, INGR_CSV]:\n",
    "    print(p, \"| exists:\", p.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dish = pd.read_csv(DISH_CSV)\n",
    "ingr = pd.read_csv(INGR_CSV)\n",
    "\n",
    "print(\"dish shape:\", dish.shape)\n",
    "print(\"ingredients shape:\", ingr.shape)\n",
    "\n",
    "display(dish.head(3))\n",
    "display(ingr.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_counts = dish[\"split\"].value_counts()\n",
    "print(\"split counts:\\n\", split_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceaabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим, чтобы один и тот же dish_id не встречался одновременно в train и в test\n",
    "leak = dish.groupby(\"dish_id\")[\"split\"].nunique()\n",
    "leak_dishes = leak[leak>1]\n",
    "print(\"дубликаты dish_id в разных сплитах:\", int((leak_dishes>0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f12453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем путь к изображению\n",
    "dish[\"image_path\"] = dish[\"dish_id\"].apply(lambda d: str(IMG_DIR / str(d) / \"rgb.png\"))\n",
    "\n",
    "# Возьмём 6 изображений\n",
    "sample = dish.sample(6, random_state=42)\n",
    "\n",
    "# Отображаем изображения\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, (_, row) in enumerate(sample.iterrows(), 1):\n",
    "    img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"dish_id: {row['dish_id']}\\n{row['total_calories']} kcal, {row['split']}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ingr_ids(s: str):\n",
    "    # 'ingr_0000000122;ingr_0000000026;...' -> ['0000000122','0000000026', ...]\n",
    "    if pd.isna(s) or not isinstance(s, str) or s.strip()==\"\":\n",
    "        return []\n",
    "    ids = [t.split(\"_\")[-1] for t in s.split(\";\") if t]\n",
    "    return ids\n",
    "\n",
    "id2name = dict(zip(ingr[\"id\"].astype(str).str.zfill(10), ingr[\"ingr\"].astype(str)))\n",
    "\n",
    "dish[\"ingr_ids\"]  = dish[\"ingredients\"].apply(parse_ingr_ids)\n",
    "dish[\"ingr_names\"] = dish[\"ingr_ids\"].apply(lambda lst: [id2name.get(x, f\"unknown_{x}\") for x in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "all_ingr = [n for lst in dish[\"ingr_names\"] for n in lst]\n",
    "cnt = Counter(all_ingr)\n",
    "top = pd.DataFrame(cnt.most_common(20), columns=[\"ingredient\",\"count\"])\n",
    "display(top)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(top[\"ingredient\"][::-1], top[\"count\"][::-1])\n",
    "plt.title(\"Top-20 ingredients\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e351f8",
   "metadata": {},
   "source": [
    "Что предсказываем:\n",
    "\n",
    "Цель: total_calories (ккал) для каждого dish_id.\n",
    "\n",
    "Формат задачи: регрессия.\n",
    "\n",
    "Мультимодальная регрессия (изображение + текст ингредиентов + масса):\n",
    "\n",
    "\n",
    "\n",
    "*   Image encoder из timm.\n",
    "*   Text encoder — bert-base-uncased из transformers. На вход — строка с ингредиентами.\n",
    "\n",
    "Метрика, по которой будем смотреть качество обучения модели - MAE. Оптимизатор: AdamW, разный LR для текстовой и визуальной частей.\n",
    "\n",
    "Аугментацию можно сделать по минимуму: масштабировать изображения, сделать Affine (имитирует небольшие сдвиги), ColorJitter(имитирует вариации освещения камеры), небольшой CoarseDropout (drop маленьких областей) — повышает устойчивость к локальным артефактам. \n",
    "\n",
    "Так как это фото блюд, здесь важны детали. Также фотографии сняты с одного и того же ракурса. \n",
    "\n",
    "\n",
    "Наблюдения по EDA:\n",
    "В датасете 555 ингредиентов, 3262 блюда. В тренировочной выборке - 2755 блюд, в тестовой - 507.\n",
    "Самые популярные инредиенты - это оливковое масло, соль и чеснок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb07129",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SEED = 42\n",
    "\n",
    "    # База данных\n",
    "    BASE_DIR = \"/content/nutrition/data/\"\n",
    "\n",
    "    # Модели\n",
    "    TEXT_MODEL_NAME  = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "    IMAGE_MODEL_NAME = \"tf_efficientnet_b0\"\n",
    "\n",
    "    # Разморозка слоёв\n",
    "    TEXT_MODEL_UNFREEZE  = \"encoder.layer.11|pooler\"\n",
    "    IMAGE_MODEL_UNFREEZE = \"blocks.6|conv_head|bn2\"\n",
    "\n",
    "    # Гиперпараметры\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 140\n",
    "    USE_AMP = True\n",
    "    NUM_WORKERS = 2\n",
    "\n",
    "    # LR и регуляризация\n",
    "    TEXT_LR  = 3e-5\n",
    "    IMAGE_LR = 1e-4\n",
    "    HEAD_LR  = 1e-3\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "\n",
    "    # Головы\n",
    "    HIDDEN_DIM  = 256\n",
    "    MASS_HIDDEN = 32\n",
    "    DROPOUT = 0.2\n",
    "\n",
    "    # Сохранение\n",
    "    SAVE_PATH = \"/data/nutrition/data/best_model.pth\"\n",
    "\n",
    "import torch\n",
    "from scripts.utils import train\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg = Config()\n",
    "\n",
    "train(cfg, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823eb77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resume(config, device, save_path):\n",
    "    seed_everything(config.SEED)\n",
    "    \n",
    "    model = MultimodalRegressor(config).to(device)\n",
    "    \n",
    "    # Загружаем сохранённые веса\n",
    "    print(f\"Загружаем веса: {save_path}\")\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Замораживаем часть слоёв чтобы уменьшить переобучение\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'text_model' in name and 'encoder.layer.0' in name:\n",
    "            param.requires_grad = False\n",
    "        if 'image_model' in name and 'blocks.0' in name:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Оптимизатор с уменьшенным LR\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(), \n",
    "        lr=config.HEAD_LR, \n",
    "        weight_decay=config.WEIGHT_DECAY  # Увеличили регуляризацию\n",
    "    )\n",
    "    \n",
    "    tr_tfms = get_transforms(config, split=\"train\")\n",
    "    te_tfms = get_transforms(config, split=\"test\")\n",
    "    \n",
    "    train_ds = CaloriesDataset(config, tr_tfms, split=\"train\")\n",
    "    val_ds = CaloriesDataset(config, te_tfms, split=\"test\")\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True, \n",
    "                             num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.USE_AMP)\n",
    "    \n",
    "    best_mae = 59.95\n",
    "    start_epoch = 141  # Продолжаем с этой эпохи\n",
    "    additional_epochs = ContinueConfig.EPOCHS  # Дополнительные эпохи\n",
    "    \n",
    "    print(f\"Продолжаем обучение с эпохи {start_epoch}...\")\n",
    "    \n",
    "    for epoch in range(start_epoch, start_epoch + additional_epochs):\n",
    "        model.train()\n",
    "        total_mae = 0\n",
    "        batches = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config.USE_AMP):\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                    \"image\": batch[\"image\"].to(device),\n",
    "                    \"mass\": batch[\"mass\"].to(device),\n",
    "                }\n",
    "                target = batch[\"target\"].to(device)\n",
    "                pred = model(**inputs)\n",
    "                loss = torch.nn.functional.l1_loss(pred, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            total_mae += torch.abs(pred - target).sum().item()\n",
    "            batches += target.size(0)\n",
    "        \n",
    "        train_mae = total_mae / batches\n",
    "        val_mae = validate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"Epoch {epoch:03d} | Train MAE: {train_mae:.2f} | Val MAE: {val_mae:.2f}\")\n",
    "        \n",
    "        if val_mae < best_mae:\n",
    "            best_mae = val_mae\n",
    "            new_save_path = f\"/data/nutrition/data/continued_best_model.pth\"\n",
    "            torch.save(model.state_dict(), new_save_path)\n",
    "            print(f\"New best, saved to {new_save_path} (MAE={best_mae:.2f})\")\n",
    "            \n",
    "            if best_mae < 50:\n",
    "                print(\"Цель достигнута! MAE < 50\")\n",
    "                break\n",
    "    \n",
    "    return best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinueConfig:\n",
    "    SEED = 42\n",
    "\n",
    "    # База данных\n",
    "    BASE_DIR = \"/content/nutrition/data/\"\n",
    "\n",
    "    TEXT_MODEL_NAME  = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "    IMAGE_MODEL_NAME = \"tf_efficientnet_b0\"\n",
    "\n",
    "    # Разморозка слоёв - размораживаем всё для тонкой настройки\n",
    "    TEXT_MODEL_UNFREEZE  = \"\"\n",
    "    IMAGE_MODEL_UNFREEZE = \"\"\n",
    "\n",
    "    # Гиперпараметры\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 60  # 60 дополнительных эпох (до 200 всего)\n",
    "    USE_AMP = True\n",
    "    NUM_WORKERS = 2\n",
    "\n",
    "    # LR и регуляризация - уменьшаем В 3-5 РАЗ для тонкой настройки\n",
    "    TEXT_LR  = 1e-5\n",
    "    IMAGE_LR = 3e-5 \n",
    "    HEAD_LR  = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "\n",
    "    HIDDEN_DIM  = 256\n",
    "    MASS_HIDDEN = 32\n",
    "    DROPOUT = 0.4\n",
    "\n",
    "    SAVE_PATH = \"/data/nutrition/data/continued_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b09a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/nutrition/data/best_model.pth\"\n",
    "\n",
    "cfg = ContinueConfig()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "final_mae = train_resume(cfg, device, save_path)\n",
    "print(f\"Финальный результат после продолжения: {final_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce205f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resume_with_scheduler(config, device, save_path):\n",
    "    seed_everything(config.SEED)\n",
    "    \n",
    "    model = MultimodalRegressor(config).to(device)\n",
    "    checkpoint = torch.load(save_path)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Заморозка (как была)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'text_model' in name and 'encoder.layer.0' in name:\n",
    "            param.requires_grad = False\n",
    "        if 'image_model' in name and 'blocks.0' in name:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=config.HEAD_LR, weight_decay=config.WEIGHT_DECAY)\n",
    "    \n",
    "    # ДОБАВЛЯЕМ ШЕДУЛЕР\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=8\n",
    "    )\n",
    "    \n",
    "    tr_tfms = get_transforms(config, split=\"train\")\n",
    "    te_tfms = get_transforms(config, split=\"test\")\n",
    "    \n",
    "    train_ds = CaloriesDataset(config, tr_tfms, split=\"train\")\n",
    "    val_ds = CaloriesDataset(config, te_tfms, split=\"test\")\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True, \n",
    "                             num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_ds, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "                           num_workers=config.NUM_WORKERS, collate_fn=collate_fn)\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.USE_AMP)\n",
    "    \n",
    "    best_mae = 52.54  # Текущий лучший\n",
    "    start_epoch = 200  # Продолжаем с этой эпохи\n",
    "    additional_epochs = 50\n",
    "    \n",
    "    print(f\"Продолжаем с MAE=52.54, добавляем шедулер\")\n",
    "    \n",
    "    for epoch in range(start_epoch, start_epoch + additional_epochs):\n",
    "        model.train()\n",
    "        total_mae = 0\n",
    "        batches = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=config.USE_AMP):\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                    \"image\": batch[\"image\"].to(device),\n",
    "                    \"mass\": batch[\"mass\"].to(device),\n",
    "                }\n",
    "                target = batch[\"target\"].to(device)\n",
    "                pred = model(**inputs)\n",
    "                loss = torch.nn.functional.l1_loss(pred, target)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            total_mae += torch.abs(pred - target).sum().item()\n",
    "            batches += target.size(0)\n",
    "        \n",
    "        train_mae = total_mae / batches\n",
    "        val_mae = validate(model, val_loader, device)\n",
    "        \n",
    "        # обновляем шедулер каждую эпоху\n",
    "        scheduler.step(val_mae)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch:03d} | Train MAE: {train_mae:.2f} | Val MAE: {val_mae:.2f} | LR: {current_lr:.2e}\")\n",
    "        \n",
    "        if val_mae < best_mae:\n",
    "            best_mae = val_mae\n",
    "            new_save_path = f\"/data/nutrition/data/continued_best_model.pth\"\n",
    "            torch.save(model.state_dict(), new_save_path)\n",
    "            print(f\"New best, saved to {new_save_path} (MAE={best_mae:.2f})\")\n",
    "            \n",
    "            if best_mae < 50:\n",
    "                print(\"Цель достигнута! MAE < 50\")\n",
    "                break\n",
    "    \n",
    "    return best_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем лучший чекпоинт\n",
    "save_path = \"/data/nutrition/data/continued_best_model.pth\"  # MAE=52.54\n",
    "\n",
    "cfg = ContinueConfig()\n",
    "cfg.EPOCHS = 50  # Ещё 50 эпох\n",
    "cfg.HEAD_LR = 5e-5  # Ещё меньше LR\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "final_mae = train_resume_with_scheduler(cfg, device, save_path)\n",
    "print(f\"Финальный результат: {final_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f351f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Звпустим обучение ещё раз с момента, где остановились, с 50 эпохами и с тем же config\n",
    "# Так как я просто запустила ячейку с тем же config, номера эпох не обновились, они снова будут с 200 до 249..\n",
    "save_path = \"/data/nutrition/data/continued_best_model.pth\"  # MAE=50.97\n",
    "\n",
    "cfg = ContinueConfig()\n",
    "cfg.EPOCHS = 50  # Ещё 50 эпох\n",
    "cfg.HEAD_LR = 5e-5  # Ещё меньше LR\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "final_mae = train_resume_with_scheduler(cfg, device, save_path)\n",
    "print(f\"Финальный результат: {final_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Лучшая модель с результатом MAE=49.93 сохранена в файл {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b55fcb",
   "metadata": {},
   "source": [
    "Этап 4. Валидация качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de548d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test_tfms = get_transforms(cfg, split=\"test\")\n",
    "test_ds   = CaloriesDataset(cfg, test_tfms, split=\"test\")\n",
    "test_dl   = DataLoader(test_ds, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                       num_workers=cfg.NUM_WORKERS, pin_memory=True,\n",
    "                       collate_fn=collate_fn)\n",
    "\n",
    "# загружаем лучшую модель\n",
    "model = MultimodalRegressor(cfg).to(device)\n",
    "best_path = \"/content/drive/MyDrive/nutrition/data/continued_best_model.pth\"\n",
    "state = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# прогон на тестовых данных\n",
    "all_preds, all_targets, dish_ids, img_paths = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dl:\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            \"image\": batch[\"image\"].to(device),\n",
    "            \"mass\": batch[\"mass\"].to(device),\n",
    "        }\n",
    "        y = batch[\"target\"].to(device)\n",
    "        pred = model(**inputs)\n",
    "\n",
    "        all_preds.extend(pred.cpu().numpy().tolist())\n",
    "        all_targets.extend(y.cpu().numpy().tolist())\n",
    "\n",
    "        dish_ids.extend(batch.get(\"dish_id\", [\"?\"] * len(pred)))\n",
    "        img_paths.extend(batch.get(\"image_path\", [\"\"] * len(pred)))\n",
    "\n",
    "all_preds   = np.array(all_preds, dtype=float)\n",
    "all_targets = np.array(all_targets, dtype=float)\n",
    "mae = np.mean(np.abs(all_preds - all_targets))\n",
    "print(f\"Финальный тестовый MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем таблицу результатов\n",
    "errors = np.abs(all_preds - all_targets)\n",
    "res_df = pd.DataFrame({\n",
    "    \"dish_id\": dish_ids,\n",
    "    \"image_path\": img_paths,\n",
    "    \"y_true\": all_targets,\n",
    "    \"y_pred\": all_preds,\n",
    "    \"abs_error\": errors,\n",
    "})\n",
    "\n",
    "worst5 = res_df.sort_values(\"abs_error\", ascending=False).head(5)\n",
    "display(worst5[[\"dish_id\", \"y_true\", \"y_pred\", \"abs_error\"]])\n",
    "\n",
    "# визуализация\n",
    "n = len(worst5)\n",
    "cols = 5\n",
    "fig, axes = plt.subplots(1, n, figsize=(4*n, 4))\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (_, row) in zip(axes, worst5.iterrows()):\n",
    "    try:\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        ax.imshow(img)\n",
    "    except:\n",
    "        ax.text(0.5, 0.5, \"no image\", ha=\"center\", va=\"center\")\n",
    "    ax.axis(\"off\")\n",
    "    title = f\"id:{row['dish_id']}\\ntrue:{row['y_true']:.0f}  pred:{row['y_pred']:.0f}\\nerr:{row['abs_error']:.0f}\"\n",
    "    ax.set_title(title, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e4796",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "Большие ошибки наблюдаются на блюдах со смешанным составом (несколько компонентов с сильно различной калорийностью).\n",
    "\n",
    "Модель недооценивает энергетическую плотность орехов и жареных компонентов.\n",
    "\n",
    "Текстовые признаки («ингредиенты») могли быть сокращены или плохо токенизированы TinyBERT’ом, из-за чего текстовая часть модели не дала достаточного вклада.\n",
    "\n",
    "На последних двух фотографиях вообще доствточно много ингредиентов смешано в одном блюде."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c2656",
   "metadata": {},
   "source": [
    "Финальный результат\n",
    "\n",
    "Модель достигла MAE = 49.93 на тестовой выборке, что соответствует требуемому уровню точности (MAE < 50).\n",
    "Проектная цель выполнена."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
